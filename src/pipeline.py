# src/pipeline.py
import torch
import os
import time
from config.settings import DEVICE, DEFAULT_POS_PROMPT, DEFAULT_NEG_PROMPT, OUTPUT_DIR
from src.image_utils import preprocess_image, get_canny_image, extract_style_features, apply_color_match
import gradio as gr

def run_style_transfer(pipe, source_image, reference_image, style_strength, custom_prompt, seed):
    """
    æ ¸å¿ƒç”Ÿæˆå‡½æ•°
    å‚æ•°:
        pipe: å·²åŠ è½½çš„æ¨¡å‹ç®¡é“
        source_image: åŸå›¾
        reference_image: å‚è€ƒå›¾
        style_strength: é£æ ¼å¼ºåº¦
        custom_prompt: ç”¨æˆ·è¾“å…¥çš„æç¤ºè¯
        seed: éšæœºç§å­
    """
    if source_image is None:
        raise gr.Error("è¯·ä¸Šä¼ æºå›¾ç‰‡ï¼")
    
    # 1. é¢„å¤„ç†
    source_image = preprocess_image(source_image)
    canny_image = get_canny_image(source_image)
    
    # 2. æ„å»ºæç¤ºè¯
    style_desc = extract_style_features(reference_image) if reference_image else ""
    full_prompt = f"{DEFAULT_POS_PROMPT}, {custom_prompt}, {style_desc}"
    print(f"ğŸ¨ ç”Ÿæˆæç¤ºè¯: {full_prompt}")
    
    # 3. è®¾ç½®ç§å­
    generator = torch.Generator(device=DEVICE).manual_seed(int(seed))
    
    # 4. æ¨ç†ç”Ÿæˆ
    result = pipe(
        prompt=full_prompt,
        negative_prompt=DEFAULT_NEG_PROMPT,
        image=source_image,           # Img2Img è¾“å…¥
        control_image=canny_image,    # ControlNet è¾“å…¥
        strength=style_strength,
        controlnet_conditioning_scale=0.5, # æ¨èæƒé‡
        guidance_scale=7.5,
        num_inference_steps=30,
        generator=generator
    ).images[0]
    
    # 5. åå¤„ç†ï¼šè‰²å½©åŒ¹é…
    if reference_image:
        result = apply_color_match(result, reference_image)
    
    # 6. è‡ªåŠ¨ä¿å­˜ç»“æœ (æ–°å¢åŠŸèƒ½)
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    save_path = os.path.join(OUTPUT_DIR, f"result_{timestamp}.png")
    result.save(save_path)
    print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜è‡³: {save_path}")
    
    return result, canny_image