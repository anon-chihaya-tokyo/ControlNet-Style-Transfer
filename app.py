import gradio as gr
import torch
from diffusers import StableDiffusionControlNetImg2ImgPipeline, ControlNetModel, DDIMScheduler
from PIL import Image
import numpy as np
import cv2
from skimage.exposure import match_histograms

print("ğŸš€ æ­£åœ¨åˆå§‹åŒ–å¸¦ ControlNet çš„é£æ ¼è¿ç§»æ¨¡å‹...")

# è®¾å¤‡é…ç½®
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"ä½¿ç”¨è®¾å¤‡: {device}")

def load_model_smart(model_class, model_id, **kwargs):
    """
    æ™ºèƒ½åŠ è½½å‡½æ•°ï¼š
    1. ä¼˜å…ˆå°è¯• local_files_only=True (å®Œå…¨ä¸è”ç½‘ï¼Œç§’å¼€)
    2. å¦‚æœæœ¬åœ°æ²¡æ–‡ä»¶ï¼Œå†è‡ªåŠ¨è”ç½‘ä¸‹è½½
    """
    try:
        print(f"ğŸ“‚ å°è¯•ç¦»çº¿åŠ è½½æœ¬åœ°ç¼“å­˜: {model_id} ...")
        # æ ¸å¿ƒä¿®æ”¹ï¼šå¼ºåˆ¶åªçœ‹æœ¬åœ°ï¼Œä¸å‘ä»»ä½•ç½‘ç»œè¯·æ±‚
        return model_class.from_pretrained(model_id, local_files_only=True, **kwargs)
    except Exception as e:
        print(f"âš ï¸ æœ¬åœ°æœªæ‰¾åˆ°æˆ–æŸå ({str(e)})")
        print(f"ğŸŒ æ­£åœ¨å°è¯•è”ç½‘ä¸‹è½½: {model_id} ...")
        # åªæœ‰æœ¬åœ°å¤±è´¥äº†ï¼Œæ‰è”ç½‘
        return model_class.from_pretrained(model_id, local_files_only=False, **kwargs)

# 1. åŠ è½½ ControlNet
# æ³¨æ„ï¼šè¿™é‡ŒæŠŠåŸæ¥çš„ ControlNetModel.from_pretrained æ¢æˆäº†æˆ‘ä»¬çš„æ™ºèƒ½å‡½æ•°
controlnet = load_model_smart(
    ControlNetModel,
    "lllyasviel/sd-controlnet-canny",  # æˆ–è€…æ˜¯ä½ æ”¹è¿‡çš„ softedge
    torch_dtype=torch.float16 if device == "cuda" else torch.float32
)

# 2. åŠ è½½ Stable Diffusion ä¸»æ¨¡å‹
# ç¡®ä¿è¿™é‡Œæ˜¯ä½ é€‰å®šçš„æœ€æ–°æ¨¡å‹ ID
model_id = "SG161222/Realistic_Vision_V6.0_B1_noVAE"  # æˆ–è€…æ˜¯ "emilianJR/epiCRealism"

pipe = load_model_smart(
    StableDiffusionControlNetImg2ImgPipeline,
    model_id,
    controlnet=controlnet,
    torch_dtype=torch.float16 if device == "cuda" else torch.float32,
    safety_checker=None
)

# ä½¿ç”¨ DDIM é‡‡æ ·å™¨
pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)

# æ˜¾å­˜ä¼˜åŒ–ç­–ç•¥ (ä¿ç•™ä½ ä¹‹å‰çš„ä¼˜åŒ–)
if device == "cuda":
    pipe.enable_model_cpu_offload()
    pipe.enable_vae_slicing()

print("âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼")
# =============================================================================
# == è¾…åŠ©å‡½æ•° ==
# =============================================================================

def preprocess_image(image, target_size=512):
    """é¢„å¤„ç†å›¾ç‰‡ï¼šè°ƒæ•´å¤§å°ä¸º 8 çš„å€æ•°"""
    if image is None:
        return None
    
    # ä¿æŒå®½é«˜æ¯”ç¼©æ”¾
    w, h = image.size
    scale = target_size / max(w, h)
    new_w, new_h = int(w * scale), int(h * scale)
    
    # ç¡®ä¿æ˜¯ 8 çš„å€æ•°ï¼ˆSD è¦æ±‚ï¼‰
    new_w = (new_w // 8) * 8
    new_h = (new_h // 8) * 8
    
    return image.resize((new_w, new_h), Image.LANCZOS)

def apply_color_match(source, reference):
    """å¼ºåˆ¶å°† source çš„è‰²è°ƒè°ƒæ•´ä¸º reference çš„è‰²è°ƒ"""
    src_arr = np.array(source)
    ref_arr = np.array(reference)
    # åŒ¹é…ç›´æ–¹å›¾
    matched = match_histograms(src_arr, ref_arr, channel_axis=-1)
    return Image.fromarray(matched.astype('uint8'))

def get_canny_image(image):
    """
    æå–å›¾ç‰‡çš„ Canny è¾¹ç¼˜å›¾
    è¿™æ˜¯ ControlNet çš„æ ¸å¿ƒï¼šå‘Šè¯‰ AI å›¾ç‰‡çš„çº¿æ¡åœ¨å“ªé‡Œ
    """
    image = np.array(image)
    
    # Canny è¾¹ç¼˜æ£€æµ‹é˜ˆå€¼
    low_threshold = 100
    high_threshold = 200
    
    image = cv2.Canny(image, low_threshold, high_threshold)
    
    # å°†å•é€šé“è¾¹ç¼˜å›¾è½¬æ¢ä¸ºä¸‰é€šé“ (RGB)ï¼Œå› ä¸º ControlNet éœ€è¦ RGB è¾“å…¥
    image = image[:, :, None]
    image = np.concatenate([image, image, image], axis=2)
    
    return Image.fromarray(image)


def extract_style_features(reference_image):
    """ä»å‚è€ƒå›¾æå–ç®€å•çš„é£æ ¼æè¿° (ä¿ç•™åŸé€»è¾‘ä½œä¸ºè¾…åŠ©)"""
    if reference_image is None:
        return ""
        
    img_array = np.array(reference_image)
    pixels = img_array.reshape(-1, 3)
    avg_color = np.mean(pixels, axis=0).astype(int)
    r, g, b = avg_color
    
    color_desc = ""
    if r > g and r > b:
        color_desc = "warm tones, reddish"
    elif g > r and g > b:
        color_desc = "cool tones, greenish"
    elif b > r and b > g:
        color_desc = "cool tones, bluish"
    else:
        color_desc = "neutral tones"
    
    brightness = np.mean(img_array)
    lighting_desc = "bright lighting" if brightness > 150 else "dark, moody lighting"
    
    return f"{color_desc}, {lighting_desc}"


# =============================================================================
# == æ ¸å¿ƒç”Ÿæˆé€»è¾‘ ==
# =============================================================================

@torch.no_grad()
def style_transfer(source_image, reference_image, style_strength=0.75, 
                   custom_prompt="", seed=42):
    """
    å¸¦ ControlNet çš„é£æ ¼è¿ç§»å‡½æ•°
    """
    
    if source_image is None:
        raise gr.Error("è¯·ä¸Šä¼ æºå›¾ç‰‡ï¼")
    
    # 1. é¢„å¤„ç†æºå›¾
    source_image = preprocess_image(source_image)
    
    # 2. åˆ¶ä½œ ControlNet éœ€è¦çš„è¾¹ç¼˜æ§åˆ¶å›¾
    canny_image = get_canny_image(source_image)
    
    # 3. æ„å»ºæç¤ºè¯
    # æå–å‚è€ƒå›¾ç‰¹å¾ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æƒ³ç”¨è‡ªåŠ¨æå–ï¼Œå¯ä»¥ç•™ç©ºï¼‰
    style_desc = extract_style_features(reference_image) if reference_image else ""
    
    # åŸºç¡€é«˜è´¨é‡è¯ + ç”¨æˆ·è¾“å…¥ + è‡ªåŠ¨æå–çš„é£æ ¼
    base_prompt = "masterpiece, best quality, high resolution"
    
    if custom_prompt:
        prompt = f"{base_prompt}, cinematic lighting, detailed texture, RAW photo, subject, 8k uhd, dslr, soft lighting, high quality, film grain,{custom_prompt}, {style_desc}"
    else:
        # é»˜è®¤æç¤ºè¯ï¼Œå¼ºè°ƒé£æ ¼åŒ–
        prompt = f"{base_prompt}, cinematic lighting, detailed texture, RAW photo, subject, 8k uhd, dslr, soft lighting, high quality, film grain,{style_desc}"
    
    negative_prompt = f"nsfw, nude, naked, cleavage, nipples, revealing clothes, lingerie, bikini, "  # æ ¸å¿ƒé˜²
    "bad anatomy, bad hands, missing fingers, extra fingers, three hands, "        # é˜²è‚¢ä½“å´©å
    "deformed, blurry, low quality, jpeg artifacts, text, watermark, signature, " # é˜²ç”»è´¨å·®
    "makeup, plastic skin, doll, 3d render, cartoon"
    
    print(f"ç”Ÿæˆæç¤ºè¯: {prompt}")
    
    # 4. è®¾ç½®éšæœºç§å­
    generator = torch.Generator(device=device).manual_seed(seed)
    
    # 5. ç”Ÿæˆ (Img2Img + ControlNet)
    result = pipe(
        prompt=prompt,
        negative_prompt=negative_prompt,
        image=source_image,           # åŸå›¾ (ç”¨äº img2img é¢œè‰²å‚è€ƒ)
        control_image=canny_image,    # æ§åˆ¶å›¾ (ç”¨äº ControlNet é”å®šç»“æ„)
        
        # å…³é”®å‚æ•°è°ƒæ•´
        strength=style_strength,             # é£æ ¼åŒ–å¼ºåº¦ (0.6-0.9 å‡å¯ï¼Œå› ä¸ºæœ‰ ControlNet é”ç»“æ„)
        controlnet_conditioning_scale=0.5,   # ControlNet æƒé‡ (1.0 = ä¸¥æ ¼éµå®ˆçº¿æ¡)
        guidance_scale=7.5,
        num_inference_steps=30,
        generator=generator
    ).images[0]
    result = apply_color_match(result, reference_image)
    return result, canny_image  # è¿”å›ç»“æœå’Œè¾¹ç¼˜å›¾ï¼ˆæ–¹ä¾¿è°ƒè¯•ï¼‰


# =============================================================================
# == Gradio ç•Œé¢ ==
# =============================================================================

with gr.Blocks(title="AI é£æ ¼è¿ç§» (ControlNetç‰ˆ)", theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    # ğŸ¨ å‡çº§ç‰ˆé£æ ¼è¿ç§»ç³»ç»Ÿ (Powered by ControlNet)
    
    **å‡çº§è¯´æ˜ï¼š** å¼•å…¥äº† ControlNet (Canny) æŠ€æœ¯ã€‚ç°åœ¨ä½ å¯ä»¥æ”¾å¿ƒè°ƒé«˜"é£æ ¼å¼ºåº¦"ï¼Œç³»ç»Ÿä¼šä¸¥æ ¼é”å®šæºå›¾ç‰‡çš„çº¿æ¡ç»“æ„ï¼Œä¸å†æ‹…å¿ƒè„¸å´©æˆ–çœ¼é•œæ¶ˆå¤±ï¼
    """)
    
    with gr.Row():
        with gr.Column(scale=1):
            gr.Markdown("### ğŸ“¤ è¾“å…¥")
            source_img = gr.Image(type="pil", label="æºå›¾ç‰‡ï¼ˆä¿ç•™ç»“æ„ï¼‰")
            reference_img = gr.Image(type="pil", label="å‚è€ƒå›¾ç‰‡ï¼ˆæä¾›é£æ ¼/é¢œè‰²å‚è€ƒï¼‰")
            
            with gr.Accordion("ğŸ”§ å‚æ•°è®¾ç½®", open=True):
                style_strength = gr.Slider(
                    0.3, 1.0, value=0.75, step=0.05,
                    label="é£æ ¼å¼ºåº¦ (å»ºè®® 0.6 - 0.9)"
                )
                custom_prompt = gr.Textbox(
                    label="é£æ ¼æè¿° (å¼ºçƒˆå»ºè®®æ‰‹åŠ¨è¾“å…¥)",
                    placeholder="ä¾‹å¦‚: oil painting style, van gogh, blue swirling sky"
                )
                seed = gr.Slider(
                    0, 999999, value=42, step=1,
                    label="éšæœºç§å­"
                )
            
            generate_btn = gr.Button("ğŸš€ å¼€å§‹ç”Ÿæˆ", variant="primary", size="lg")
        
        with gr.Column(scale=1):
            gr.Markdown("### âœ¨ è¾“å‡º")
            output_img = gr.Image(type="pil", label="é£æ ¼è¿ç§»ç»“æœ")
            
            with gr.Accordion("ğŸ‘€ æŸ¥çœ‹ç»“æ„æ§åˆ¶å›¾ (è°ƒè¯•ç”¨)", open=False):
                canny_debug_img = gr.Image(type="pil", label="ç³»ç»Ÿæå–çš„è¾¹ç¼˜å›¾")

    # ç»‘å®šæŒ‰é’®
    generate_btn.click(
        fn=style_transfer,
        inputs=[source_img, reference_img, style_strength, custom_prompt, seed],
        outputs=[output_img, canny_debug_img]
    )

print("ğŸŒŸ å¯åŠ¨ Gradio ç•Œé¢...")
demo.launch(server_name="0.0.0.0", server_port=7860, share=False)